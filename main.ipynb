{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35f501ef",
   "metadata": {},
   "source": [
    "# GameStats2Text: Main Training Notebook\n",
    "\n",
    "This notebook implements the end-to-end pipeline for the GameStats2Text model:\n",
    "\n",
    "1. Load and preprocess the dataset\n",
    "2. Split into train/validation/test sets (75/20/5)\n",
    "3. Set up PyTorch data loaders\n",
    "4. Initialize model components\n",
    "5. Train the model\n",
    "6. Evaluate performance\n",
    "7. Generate example outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a042df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp-proj/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from transformers import GPT2Tokenizer, get_linear_schedule_with_warmup\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Import project modules\n",
    "from src.process.stats_encoder import StatsEncoder\n",
    "from src.models.encoder import GameStats2TextModel\n",
    "from src.models.generator import GameStats2TextGenerator\n",
    "from src.process.setupData import GameStatsTextDataset, collate_fn\n",
    "\n",
    "# Set seed for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9e9a8a",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7febe7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1193, 13)\n",
      "\n",
      "Column names:\n",
      "['date', 'MP', 'PTS', 'FG%', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'Result', 'question', 'answer']\n",
      "\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>MP</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FG%</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>Result</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-05-21</td>\n",
       "      <td>45:22</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>I know you say that you're a football player, ...</td>\n",
       "      <td>(Laughing) It was definitely a physical game t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-05-21</td>\n",
       "      <td>45:22</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>The last play there, Coach said that was kind ...</td>\n",
       "      <td>No, I go for the winning play.  If two guys co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-05-21</td>\n",
       "      <td>45:22</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>As a franchise player, how do you justify only...</td>\n",
       "      <td>No, you've just got to take what's there.  It'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-05-21</td>\n",
       "      <td>45:22</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Coach said that a couple of adjustments need t...</td>\n",
       "      <td>We definitely played pretty well.  Both teams ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-05-21</td>\n",
       "      <td>45:22</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Third quarter, again, you guys fell behind 7-0...</td>\n",
       "      <td>Not sure.  It's just something that we've got ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     MP   PTS    FG%   TRB  AST  STL  BLK  TOV   PF  Result  \\\n",
       "0  2007-05-21  45:22  10.0  0.333  10.0  9.0  4.0  1.0  2.0  1.0       0   \n",
       "1  2007-05-21  45:22  10.0  0.333  10.0  9.0  4.0  1.0  2.0  1.0       0   \n",
       "2  2007-05-21  45:22  10.0  0.333  10.0  9.0  4.0  1.0  2.0  1.0       0   \n",
       "3  2007-05-21  45:22  10.0  0.333  10.0  9.0  4.0  1.0  2.0  1.0       0   \n",
       "4  2007-05-21  45:22  10.0  0.333  10.0  9.0  4.0  1.0  2.0  1.0       0   \n",
       "\n",
       "                                            question  \\\n",
       "0  I know you say that you're a football player, ...   \n",
       "1  The last play there, Coach said that was kind ...   \n",
       "2  As a franchise player, how do you justify only...   \n",
       "3  Coach said that a couple of adjustments need t...   \n",
       "4  Third quarter, again, you guys fell behind 7-0...   \n",
       "\n",
       "                                              answer  \n",
       "0  (Laughing) It was definitely a physical game t...  \n",
       "1  No, I go for the winning play.  If two guys co...  \n",
       "2  No, you've just got to take what's there.  It'...  \n",
       "3  We definitely played pretty well.  Both teams ...  \n",
       "4  Not sure.  It's just something that we've got ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_path = 'data/dataset.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Display basic info\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(\"\\nColumn names:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"\\nSample data:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f63b2b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical summary of numeric columns:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PTS</th>\n",
       "      <th>FG%</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1193.000000</td>\n",
       "      <td>1193.000000</td>\n",
       "      <td>1193.000000</td>\n",
       "      <td>1193.000000</td>\n",
       "      <td>1193.000000</td>\n",
       "      <td>1193.000000</td>\n",
       "      <td>1193.000000</td>\n",
       "      <td>1193.000000</td>\n",
       "      <td>1193.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.678122</td>\n",
       "      <td>0.499261</td>\n",
       "      <td>9.590947</td>\n",
       "      <td>7.499581</td>\n",
       "      <td>1.554065</td>\n",
       "      <td>0.953898</td>\n",
       "      <td>3.714166</td>\n",
       "      <td>2.433361</td>\n",
       "      <td>0.539816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.878770</td>\n",
       "      <td>0.111476</td>\n",
       "      <td>3.377579</td>\n",
       "      <td>2.790842</td>\n",
       "      <td>1.191681</td>\n",
       "      <td>1.012698</td>\n",
       "      <td>1.956218</td>\n",
       "      <td>1.292386</td>\n",
       "      <td>0.498621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.429000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.588000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.846000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               PTS          FG%          TRB          AST          STL  \\\n",
       "count  1193.000000  1193.000000  1193.000000  1193.000000  1193.000000   \n",
       "mean     29.678122     0.499261     9.590947     7.499581     1.554065   \n",
       "std       8.878770     0.111476     3.377579     2.790842     1.191681   \n",
       "min       7.000000     0.200000     2.000000     2.000000     0.000000   \n",
       "25%      24.000000     0.429000     7.000000     5.000000     1.000000   \n",
       "50%      29.000000     0.500000     9.000000     8.000000     2.000000   \n",
       "75%      35.000000     0.588000    12.000000     9.000000     2.000000   \n",
       "max      51.000000     0.846000    18.000000    13.000000     5.000000   \n",
       "\n",
       "               BLK          TOV           PF       Result  \n",
       "count  1193.000000  1193.000000  1193.000000  1193.000000  \n",
       "mean      0.953898     3.714166     2.433361     0.539816  \n",
       "std       1.012698     1.956218     1.292386     0.498621  \n",
       "min       0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     2.000000     2.000000     0.000000  \n",
       "50%       1.000000     4.000000     2.000000     1.000000  \n",
       "75%       2.000000     5.000000     3.000000     1.000000  \n",
       "max       3.000000     8.000000     6.000000     1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display statistical summary\n",
    "print(\"Statistical summary of numeric columns:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "315e6b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "date        0\n",
       "MP          0\n",
       "PTS         0\n",
       "FG%         0\n",
       "TRB         0\n",
       "AST         0\n",
       "STL         0\n",
       "BLK         0\n",
       "TOV         0\n",
       "PF          0\n",
       "Result      0\n",
       "question    0\n",
       "answer      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf79f7e",
   "metadata": {},
   "source": [
    "## 2. Data Preparation and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d927cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'MP' (minutes played) from \"MM:SS\" to float minutes if needed\n",
    "if 'MP' in df.columns and df['MP'].dtype == 'object':\n",
    "    df['MP'] = df['MP'].apply(lambda x: float(str(x).split(':')[0]) + float(str(x).split(':')[1]) / 60.0 if ':' in str(x) else float(x))\n",
    "\n",
    "# Make sure all feature columns are numeric\n",
    "feature_cols = [c for c in df.columns if c not in ['date', 'question', 'answer']]\n",
    "df[feature_cols] = df[feature_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values if any\n",
    "if df.isnull().sum().sum() > 0:\n",
    "    print(f\"Dropping {df.isnull().any(axis=1).sum()} rows with NaN values\")\n",
    "    df = df.dropna()\n",
    "    print(f\"New dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84f5fcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp-proj/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create the full dataset\n",
    "tokenizer_name = 'gpt2'\n",
    "max_length = 256\n",
    "\n",
    "full_dataset = GameStatsTextDataset(\n",
    "    csv_file=data_path,\n",
    "    tokenizer_name=tokenizer_name,\n",
    "    max_length=max_length\n",
    ")\n",
    "\n",
    "# Get the tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_name)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b52df99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size: 1193\n",
      "Training set size: 894\n",
      "Validation set size: 238\n",
      "Test set size: 61\n"
     ]
    }
   ],
   "source": [
    "# Get dataset size and calculate split sizes\n",
    "dataset_size = len(full_dataset)\n",
    "train_size = int(0.75 * dataset_size)\n",
    "val_size = int(0.20 * dataset_size)\n",
    "test_size = dataset_size - train_size - val_size\n",
    "\n",
    "print(f\"Total dataset size: {dataset_size}\")\n",
    "print(f\"Training set size: {train_size}\")\n",
    "print(f\"Validation set size: {val_size}\")\n",
    "print(f\"Test set size: {test_size}\")\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    full_dataset, [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35a01db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "batch_size = 16\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19311a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample batch shapes:\n",
      "stats: torch.Size([16, 10])\n",
      "input_ids: torch.Size([16, 256])\n",
      "attention_mask: torch.Size([16, 256])\n",
      "labels: torch.Size([16, 256])\n",
      "\n",
      "Sample question: As far as Chris, we know he hurt his ankle the other night  He says it's been just not happening for him the entire series, and he's not sure why  Any thoughts on Chris?\n",
      "Sample answer: I mean, we can state the obvious; they're both struggling  Chris is struggling with his shot, and him hurting his ankle didn't help him a lot as well  I think he will find it  He will find it  It's my job as a leader to keep him motivated, to let him know how important he is to our movement, to our chances of returning to The Finals. The best thing about this opportunity is right here we worked all season long to get home‑court advantage  If we ever had an opportunity or we put ourselves in position where we weren't taking care of business on the road, we always have one more to fall back on at home  This is the position we're in and those guys as professionals, as champions, we'll figure it out  And me as the leader, I'll have to help them figure it out.\n",
      "Sample stats: tensor([42.2833, 29.0000,  0.4760,  7.0000,  6.0000,  2.0000,  1.0000,  4.0000,\n",
      "         2.0000,  0.0000])\n"
     ]
    }
   ],
   "source": [
    "# Check a batch from the training loader\n",
    "sample_batch = next(iter(train_loader))\n",
    "print(\"Sample batch shapes:\")\n",
    "for k, v in sample_batch.items():\n",
    "    print(f\"{k}: {v.shape}\")\n",
    "\n",
    "# Decode a sample to verify data is loaded correctly\n",
    "sample_idx = 0\n",
    "sample_question = tokenizer.decode(sample_batch['input_ids'][sample_idx], skip_special_tokens=True)\n",
    "sample_answer = tokenizer.decode(sample_batch['labels'][sample_idx], skip_special_tokens=True)\n",
    "print(f\"\\nSample question: {sample_question}\")\n",
    "print(f\"Sample answer: {sample_answer}\")\n",
    "print(f\"Sample stats: {sample_batch['stats'][sample_idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797830d8",
   "metadata": {},
   "source": [
    "## 3. Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45282937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats input dimension: 10\n"
     ]
    }
   ],
   "source": [
    "# Get stats input dimension from the dataset\n",
    "stats_input_dim = full_dataset.stats.shape[1]\n",
    "print(f\"Stats input dimension: {stats_input_dim}\")\n",
    "\n",
    "# Model hyperparameters\n",
    "stats_hidden_dims = [128, 64]\n",
    "stats_output_dim = 32\n",
    "gpt_model_name = 'gpt2'\n",
    "fusion_method = 'concat'  # 'concat' or 'add'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "638c932f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GameStats2TextGenerator(\n",
      "  (stats_encoder): StatsEncoder(\n",
      "    (encoder): Sequential(\n",
      "      (0): Linear(in_features=10, out_features=128, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): Dropout(p=0.1, inplace=False)\n",
      "      (6): Linear(in_features=64, out_features=32, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (gpt2): GPT2LMHeadModel(\n",
      "    (transformer): GPT2Model(\n",
      "      (wte): Embedding(50257, 768)\n",
      "      (wpe): Embedding(1024, 768)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "      (h): ModuleList(\n",
      "        (0-11): 12 x GPT2Block(\n",
      "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): GPT2Attention(\n",
      "            (c_attn): Conv1D(nf=2304, nx=768)\n",
      "            (c_proj): Conv1D(nf=768, nx=768)\n",
      "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): GPT2MLP(\n",
      "            (c_fc): Conv1D(nf=3072, nx=768)\n",
      "            (c_proj): Conv1D(nf=768, nx=3072)\n",
      "            (act): NewGELUActivation()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      "  )\n",
      "  (proj): Linear(in_features=800, out_features=768, bias=True)\n",
      ")\n",
      "Total parameters: 125066720\n"
     ]
    }
   ],
   "source": [
    "# Initialize the generator model\n",
    "model = GameStats2TextGenerator(\n",
    "    stats_input_dim=stats_input_dim,\n",
    "    stats_hidden_dims=stats_hidden_dims,\n",
    "    stats_output_dim=stats_output_dim,\n",
    "    gpt_model_name=gpt_model_name,\n",
    "    fusion_method=fusion_method\n",
    ")\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Display model summary\n",
    "print(model)\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfa150d",
   "metadata": {},
   "source": [
    "## 4. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f46413a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "num_epochs = 1\n",
    "learning_rate = 5e-5\n",
    "weight_decay = 0.01\n",
    "warmup_steps = 100\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Learning rate scheduler\n",
    "total_steps = len(train_loader) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps=warmup_steps, \n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c9d5b9",
   "metadata": {},
   "source": [
    "## 5. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d52be46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation functions\n",
    "def train_epoch(model, dataloader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    from tqdm import tqdm as std_tqdm\n",
    "    progress_bar = std_tqdm(dataloader, desc=\"Training\")\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        # Move batch to device\n",
    "        stats = batch['stats'].to(device)\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # Replace padding token id with -100 so it's ignored in loss computation\n",
    "        labels = torch.where(labels == tokenizer.pad_token_id, -100, labels)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            stats=stats,\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    # Use standard tqdm here too\n",
    "    from tqdm import tqdm as std_tqdm\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in std_tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            # Move batch to device\n",
    "            stats = batch['stats'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Replace padding token id with -100\n",
    "            labels = torch.where(labels == tokenizer.pad_token_id, -100, labels)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(\n",
    "                stats=stats,\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "    return epoch_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ea8756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/56 [00:00<?, ?it/s]`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "Training: 100%|██████████| 56/56 [04:50<00:00,  5.18s/it, loss=6.07]\n",
      "Evaluating: 100%|██████████| 15/15 [00:21<00:00,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 6.6974, Validation loss: 6.0950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_model_path = 'best_model.pt'\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scheduler, device)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss = evaluate(model, val_loader, device)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    print(f\"Train loss: {train_loss:.4f}, Validation loss: {val_loss:.4f}\")\n",
    "    \n",
    "    Save best mode l\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"Model saved to {best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1270d05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to best_model.pt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if val_loss < best_val_loss:\n",
    "    best_val_loss = val_loss\n",
    "    torch.save(model.state_dict(), best_model_path)\n",
    "    print(f\"Model saved to {best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7d24bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIjCAYAAAA0vUuxAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAARppJREFUeJzt3Qvcl/P9P/BPdEYkISRtTkUOU4y2kVPMaY77UYQtzCmH+dGcCrOFTRs/zFBjw2aO24ScT1H5OR/CHCKFSLFI9P0/3p/f/3s/7rvuuu5vug/V8/l4XO77e32v8/VR16vP4WpWKpVKCQAAgPlaZv5fAQAAEAQnAACAAoITAABAAcEJAACggOAEAABQQHACAAAoIDgBAAAUEJwAAAAKCE4AAAAFBCeAJujQQw9N66yzzkKtO2TIkNSsWbO0JHvrrbfyOY4cObLB9x37jWtcFscQ8+KYisQ9jXvbVMoKAHUnOAFUIB6Q6zI9+OCDjX2oS73jjz8+34vXX399vsucfvrpeZnnnnsuNWXvvfdeDmvPPPNMamrh9aKLLmrsQwFoEM0bZjcAS4brrruuxudrr702jR49ep753bp1+0b7+eMf/5jmzJmzUOueccYZ6bTTTktLu379+qVLLrkkXX/99emss86qdZkbbrgh9ejRI22yySYLvZ+DDz44/dd//Vdq1apVqs/gNHTo0FyztNlmmy2ysgJA3QlOABXo379/jc9PPPFEDk5zz5/bzJkzU9u2beu8nxYtWiz0MTZv3jxPS7utttoqrbvuujkc1RacxowZk958883061//+hvtZ9lll81TY/kmZQWAutNUD2AR22677dLGG2+cnnrqqfSDH/wgB6Zf/OIX+bvbb7897bbbbmmNNdbINRTf/va307nnnpu+/vrrBfZbqd4s6sorr8zrxfq9evVK48aNK+zjFJ+PPfbYdNttt+Vji3U32mijdNddd81z/NHMsGfPnql169Z5P3/4wx/q3G/qkUceSfvvv39ae+218z46d+6cTjzxxPT555/Pc37LL798mjRpUvrRj36Uf+/YsWP6+c9/Ps+1+OSTT/LyK664YlpppZXSgAED8ry61jq98sor6X//93/n+S5qouKcDjzwwPTll1/mcLXFFlvk/Sy33HLp+9//fnrggQcK91FbH6dSqZTOO++8tNZaa+X736dPn/Tiiy/Os+7HH3+czzlqveIatGvXLu26667p2WefrXE/4j6Hww47rKo5aLl/V219nP7zn/+kk08+OV//uA8bbLBBLjtxXAtbLhbWBx98kH7yk5+k1VZbLZepTTfdNP3pT3+aZ7kbb7wxX/8VVlghX4e4Jr/73e+qvp89e3audVtvvfXydjp06JC+973v5X+4AGgI/kkSoB589NFH+QE4mnBFbVQ8NIZ42I0H5JNOOin/vP/++/MD+4wZM9KFF15YuN142P/000/TkUcemR96L7jggrTPPvukN954o7Dm4dFHH0233HJLOvroo/PD6e9///u07777pokTJ+aH0PD000+nXXbZJXXq1Ck/pEaIOeecc3KoqYubbrop16797Gc/y9scO3Zsbi737rvv5u+qi2337ds31wzFQ/29996bfvOb3+SwFuuHeNDfa6+98rEfddRRuQnkrbfemsNTXYNTnEdct+985zs19v23v/0th6MIeVOnTk1XXXVVDlEDBw7M1/jqq6/OxxfnMHfzuCJxTyM4/fCHP8xTBLedd945B7Tq4r5FaImw2bVr1/T+++/noLrtttuml156KQfsOOe4B7HNI444Ih9z2GabbWrdd1yzPffcM4e+CCxx7HfffXc65ZRTclC9+OKLKy4XCysCc/xDQvQzi4AW5xjlIMJehN9Bgwbl5SL8xLXfYYcd0rBhw/K8l19+OT322GNVy0R4/9WvfpV++tOfpi233DL/PzN+/Ph8bXfaaadvdJwAdVICYKEdc8wx8U/4NeZtu+22ed4VV1wxz/IzZ86cZ96RRx5Zatu2bemLL76omjdgwIBSly5dqj6/+eabeZsdOnQoffzxx1Xzb7/99jz/H//4R9W8s88+e55jis8tW7Ysvf7661Xznn322Tz/kksuqZq3xx575GOZNGlS1bzXXnut1Lx583m2WZvazu9Xv/pVqVmzZqW33367xvnF9s4555way26++ealLbbYourzbbfdlpe74IILquZ99dVXpe9///t5/ogRIwqPqVevXqW11lqr9PXXX1fNu+uuu/L6f/jDH6q2OWvWrBrrTZs2rbTaaquVDj/88BrzY724xmVxDDEv7lH44IMP8rXebbfdSnPmzKla7he/+EVeLs69LO559eMKsZ1WrVrVuDbjxo2b7/nOXVbK1+y8886rsdx+++2X70P1MlDXclGbcpm88MIL57vM8OHD8zJ//vOfq+Z9+eWXpa233rq0/PLLl2bMmJHnDRo0qNSuXbt8H+Zn0003zdcUoLFoqgdQD6LJUzSrmlubNm2qfo9ajajpiBqEqKWJJmVFfvzjH6f27dtXfS7XPkTNRZEdd9wx1+aUxYAI0SSqvG7UwkStTzSdi5qOsugnFLVndVH9/KK5WJxf1IzEM3rUZs0tapGqi/Opfi533nln7q9VroEK0Z/ouOOOS3UVNX5R4/Xwww9XzYsaqJYtW+aanvI243OIgRaiCd1XX32VmyzW1sxvQeIaRs1SHGP15o0nnHBCreVkmWWWqbr+UVMZNZHRtK7S/Va/ZnE+MapgddF0L+7DqFGjKioX30Qcy+qrr55rk8qiZjSO7bPPPksPPfRQnhdNMKO8LKjZXSwTzR1fe+21b3xcAAtDcAKoB2uuuWbVg3h18eC3995753408XAaTeDKA0tMnz69cLvRrKy6coiaNm1axeuW1y+vG31RomlVBKW51TavNtG8K5phrbzyylX9lqLZWW3nF/1U5m4CWP14wttvv52bDca2qotgUVfRXDKCRISl8MUXX+TmfhEGq4fQ6HcToaHcfyaO7V//+led7kt1ccwh+uJUF9urvr9ySIumc7FshKhVVlklLxfDo1e63+r7j+Abze5qG+mxfHx1LRffROwrzq0cDud3LNFMcP3118/3JPqFHX744fP0s4rmitG8L5aL/k/R9LCpDyMPLFkEJ4B6UL3mpSwe+iJERMf/eAj8xz/+kf+Fvdynoy5DSs9v9La5O/0v6nXrImpMoq9JhI1TTz01992J8ysPYjD3+TXUSHSrrrpqPq6bb745DzAQ1z1q+6L/U9mf//znHPii5iX6NsVDexz79ttvX69DfZ9//vm5v1sMIhLHEH2RYr8xQENDDTFe3+Wirvco3lF1xx13VPXPihBVvS9bXKN///vf6ZprrskDWUSftOi3Fj8BGoLBIQAaSIyOFk2xoiN+PASWxZDYTUE8vEZtS20vjF3QS2TLnn/++fTqq6/mmptDDjmkav43GfWsS5cu6b777svNuqrXOk2YMKGi7URIijAUzdSi5ilq+/bYY4+q7//+97+nb33rW/neVG9ed/bZZy/UMYdoUhbbLPvwww/nqcWJ/caIexHW5g7ZUftUVpcRDavvP5oLRjisXutUbgpaPr6GEPuKWqEIgdVrnWo7lqihjXsSUywftVAxUMaZZ55ZVeMZNZnRBDamKBPx/1EMGhEDRgDUNzVOAA2k/C/71f8lP/rCXHbZZampHF/0d4maonjhavXQNHe/mPmtP/f5xe/Vh5SuVIxIF32NLr/88ho1WzFSXyWi31YMCx7XOs4lRiKMkLigY3/yySfzu54qFdcw+vHEMVbf3vDhw+dZNvY7d81OjDoXo99VF8Ojh7oMwx7XLK7RpZdeWmN+NAmMAFbX/mqLQhzLlClT0l//+teqeXE/49pEEC4344x/UKguQlb5pcSzZs2qdZlYPwJV+XuA+qbGCaCBxCAJ0Xckmh9F5/h4iL3uuusatElUkfjX+3vuuSf17t07D8hQfgCPplHRlGpBNtxww9zULd5LFA/+UasTzeO+SV+ZqH2IYznttNPye5K6d++ea4Uq7f8TD9kRnsr9nKo30wu777573m70P4v3bEUt4BVXXJH3FzUblSi/jyqGzo7tRniIgTEisFWvRSrvN5ptRg1KlI+otfvLX/5So6YqxHWNwRHimKIWKYJUDOMew3vXds2iFuv000/P1yzemxT3NN4hFgNUVB8IYlGIGsHoNza3uN4xfHrUGkUzyHivWbxvKmrZYpjxCJLlGrGoMYoBOaJpZPRxir5PEa5iKPVyf6i4FzG0ebzrKWqeYijy2FYMcw7QEAQngAYSAw7885//zKObnXHGGTlExcAQ8e6aeF9QUxAPpfGAHw/+0UQqXqAaD/bxTp2iUf+iliX6D0UojNAQNToRROLBNh7eF0bUPES/l3jgjz5AETajD0y872nzzTevaFsRliI4xWAT8YBeXTzYR81IPORHP6N4SI/9Re1PNLGsVLzDKc4/gk7014mQE+ElQll18WLkGE0ujitqZaLPTvQRi6A497WNJpCDBw/OIxFGrc2IESNqDU7laxbvfYptxnIRWOI9YVH2FrVoAlnbC3NjnxG44/rF+cTxx7uXYmCPOKa45mXx/0G82DlqBKNWLUbiixEkI8iXm/hFuYrziusYtUzRzC+ucwwSAdAQmsWY5A2yJwAWW1F7YChoAJZm+jgBUEMMSV5dhKV4H080kwKApZUaJwBqiKZs0Ywq+tlEX5MYmCGaRkU/nbnfTQQASwt9nACoYZdddkk33HBD7vMTL2Xdeuut8/uGhCYAlmZqnAAAAAro4wQAAFBAcAIAACiw1PVxmjNnTnrvvffyS/fifSAAAMDSqVQqpU8//TStscYaVe+Nm5+lLjhFaIoXOgIAAIR33nknrbXWWmlBlrrgFDVN5YvTrl27xj4c5mP27Nn57fA777xzatGiRWMfDosBZYZKKTNUSpmhUspM0zdjxoxcqVLOCAuy1AWncvO8CE2CU9P+g6Zt27b5HvmDhrpQZqiUMkOllBkqpcwsPurShcfgEAAAAAUEJwAAgAKCEwAAQIGlro8TAABNc1jor776Kn399ddpSerj1Lx58/TFF18sUee1uIn+Zcsuu+w33o7gBABAo/ryyy/T5MmT08yZM9OSFgZXX331PJqz94c2nrj2MdT48ssv/422IzgBANBo5syZk958881cIxAvIW3ZsuUSEzLi3D777LP8wF70clXqL7x++OGH6d13303rrbfeN6p5EpwAAGjU2qYIGPEunRi6e0kS5xXn17p1a8GpEXXs2DG99dZbuenkNwlO7iAAAI1OsKC+LKoaTCUUAACggOAEAABQQHACAIAmYJ111knDhw+v8/IPPvhgbob2ySef1Otx8X8EJwAAqECElQVNQ4YMWajtjhs3Lh1xxBF1Xn6bbbbJw7ivuOKKqT4JaE0kOE2aNCn1798/dejQIbVp0yb16NEjjR8/fr7LH3roobUW0I022qhBjxsAgKVThJXyFDVE7dq1qzHv5z//+Twv9q3r6G+VjCwYQ7fHe6KWlOHbm7pGDU7Tpk1LvXv3zm/zHTVqVHrppZfSb37zm9S+ffv5rvO73/2uRsGMF4qtvPLKaf/992/QYwcAoH5E2Jj55VcNPsV+6yLCSnmK2p4ILuXPr7zySlphhRXys22vXr3Saqutlh599NH073//O+211175c7zXKb679957F9hUL7Z71VVXpb333jsHqngP0R133DHfmqCRI0emlVZaKd19992pW7dueT+77LJLfmYuixB3/PHH5+Wi4uLUU09NAwYMSD/60Y++0TP9IYcckp/h4zh33XXX9Nprr1V9//bbb6c99tgjf7/ccsvlCo8777yzat1+/frl0BiVKHGOI0aMSE1Ro77HadiwYXnM/uoXp2vXrgtcJwpn9erI2267LV/www47rF6PFQCAhvH57K9T97PubvD9vnRO39S25aJ5PD7ttNPSBRdckFZdddX8vButrH74wx+mX/7yl6lVq1bp2muvzWFiwoQJae21157vdoYOHZq3c+GFF6ZLLrkkh4wIIlFxUJuZM2emiy66KF133XV5iPdo2RU1YH/5y1+qnr/j93j+jnAVlRLxPN2nT5+FPtdDDz00B6UIdVH7FmEszjUqRaKC5Jhjjsnvs3r44YdzcIr5EerCmWeemT9H0FxllVXS66+/nj7//PPUFDVqcIqL27dv31xb9NBDD6U111wzHX300WngwIF13sbVV1+ddtxxx9SlS5dav581a1aeymbMmJF/xguwYqJpKt8b94i6UmaolDJDpZSZ+hHXM2p64mWxMYXyz4ZW/RgqWae2n9HPKZ5RP/3001wDFUEnuqRUD0S33npruv3223OwKCtfi7KoDfrxj3+cfz/vvPPS73//+/TEE0/kmqTq+yxPcT0vu+yy9O1vfzt/F9s+99xzq5aN8BWhLmq/Qmwvan/m3u/8znHOXMuUA9MjjzyS+1yFCG3xbH7LLbfk5/yJEyemffbZp6prTdSslbcXIXCzzTZL3/nOd/K8cohclGUgthXnV9sLcCv5/7lRg9Mbb7yRLr/88nTSSSelX/ziF7lDXFQdRnvNKCRF3nvvvZxOr7/++vku86tf/SoXzLndc889S9zbqZdEo0ePbuxDYDGjzFApZYZKKTOLVvPmzXMTt88++yzXSoR4yB1z0ncb/Fhmf/6fNOOLyvoLffHFF/l4y/84HzU+YYMNNsihKcTPOL+o7Yln0ClTpqSvv/4616xE8CivGw/4sb3y57DuuuvW+BwhLIJIzCvvK7YftUuxbjzfRrO38jrRUuuDDz7In6dPn57ef//91L179xrb3GSTTXITvurzqpt7P9U99dRT+R5G7VV5/ahliuN+9tlncyXJT3/603TyySfn5/btttsu17RtvPHGedlo4hfP/THGQdR67bbbbmmrrbZKi1KUq7jWUeM1d3+z8rk1+eAUhaNnz57p/PPPz58333zz9MILL6QrrriiTsHpT3/6U26fuaA2mYMHD87BrCxuaFSX7rzzzrkqkaYp0n/8xbTTTjvl//mgiDJDpZQZKqXM1I942I8+69F0q3Xr1lXz63ecuEUnjjn6GZWfK8v/MB9hMEJOucYpmq9Fn6ZodhehIvrzHHDAATXWjVAS26v+jBq/V/8cy0QlQ8wr7yu2H59j3Sib1ZePZSLYxbxyH65oLld9mQg+8Vw+v2fjufdT23cxv3ptTvweTRJj/rHHHptruP71r3/l/4e233773Jww5u+7777pBz/4Qa71iusTz/XRAi2aJi7KMhbXO/ZTvYyF+YXFJhecOnXqlBNvdZFWb7755sJ148Zfc8016eCDD86FZ37ihsU0tyhU/tBr+twnKqXMUCllhkopM4tW1LxEeIhAMHdtxuKgfMy1/SyPdhc/H3/88dwXKIJCiBqot956K9fAVD/v8rWovv25r0t5XvV9zf25tuOLwRlicIqoJYr9lq//008/nZvLze/6z72f6qL5XdTiRMuxclO9jz76KPfdiu/Ky0fTvQhEMUXFRgx6ES3NQhxTjFcQ0x/+8Id0yimn5AHjFpXyvajt/91K/l9u1OAUI+rFRa3u1VdfnW9/peqiT1R0HvvJT35Sj0cIAADfXIwWF31+oplaPMTHoAiN0ZfruOOOy11ZotZrww03zH2eYqC1ugxp/vzzz+dap7JYZ9NNN821STFGQYSe+D76UMXYBeV+VCeccEIeaW/99dfP+3rggQdyZUk466yz0hZbbJFDVoxL8M9//rPqu6amUYPTiSeemJNpNNWLqsqxY8emK6+8Mk9lkUhjFJIYeWTuQSGi/WO5fSQAADRVv/3tb9Phhx+en31j9LhouldJM7FFJfYbfayib1E0p4sX7kY/pLkHTajND37wgxqfY52obYoR+gYNGpR233333J+o3PSuXJsTtVoxSMW7776bm+7FwBYXX3xx/i5ajsXzftS+RXO673//++nGG29MTVGzUl0HrK8nkSrjYkXHuBiKPPojVR9VL6o040LGOPVl0bEtmvnF8ImVjMAXooBGJ7nYhj5OTbsdefwPF0NZag5BXSgzVEqZoVLKTP2I/idvvvlmfg6cu//J4i5qlOLZM545m2ozxDjGqOGJSowYfW9pK2MzKsgGjVrjFCKZxjQ/8SKvucXJVTICBgAA8H8vo42R/bbddtvcNO7SSy/NoeKggw5q7ENr8ppm9AUAABa5qPmKiolevXrl8Qai31KMZtdU+xU1JY1e4wQAADSMeC3PY4891tiHsVhS4wQAAFBAcAIAACggOAEAABQQnAAAAAoITgAAAAUEJwAAgAKCEwAANILtttsunXDCCVWf11lnnTR8+PAFrtOsWbN02223feN9L6rtLE0EJwAAqMAee+yRdtlll1q/e+SRR3Ioee655yre7rhx49IRRxyRFqUhQ4akzTbbbJ75kydPTrvuumuqTyNHjkwrrbRSWlIITgAAUIGf/OQnafTo0endd9+d57sRI0aknj17pk022aTi7Xbs2DG1bds2NYTVV189tWrVqkH2taQQnAAAaFpKpZS+/E/DT7HfOth9991zyIkaleo+++yzdNNNN+Vg9dFHH6WDDjoode/ePS2//PKpR48e6YYbbljgduduqvfaa6+lH/zgB6l169Z5OxHW5nbqqaem9ddfPweub33rW+nMM89Ms2fPzt/F8Q0dOjQ9++yzuRYspvIxz91U7/nnn0/bb799atOmTerQoUOu+YrzKTv00EPTj370o3TRRRelTp065WWOOeaYqn0tjIkTJ6a99torX5927dqlAw44IL3//vtV38dx9+nTJ62wwgr5+y222CKNHz8+f/f222/nmr/27dun5ZZbLm200UbpzjvvTPWpeb1uHQAAKjV7Zkrnr9Hw+/3Feym1XK5wsebNm6dDDjkkh5DTTz89h5AQoenrr79OBx54YA4d8aAf4SKCxqhRo9LBBx+cvv3tb6ctt9yycB9z5sxJ++yzT1pttdXSk08+maZPn16jP1RZhIo4jjXWWCOHn4EDB+Z5//3f/51+/OMfpxdeeCHddddd6d57783Lr7jiivNs4z//+U/q27dv2nrrrXNzwQ8++CD99Kc/Tccee2yNcPjAAw/kc4mfr7/+et5+NAOMfVYqzq8cmh566KH01Vdf5WsV23zwwQfzMv369Uubb755uvzyy9Oyyy6bnnnmmdSiRYv8XSz75ZdfpocffjgHp5deeilvqz4JTgAAUKHDDz88XXjhhfmhPwZ5KDfT23fffXM4ienkk09OM2bMyLUlxx13XLr77rvT3/72tzoFpwg6r7zySl4nQlE4//zz5+mXdMYZZ9Sosfr5z3+ebrzxxhycovYowkQEvWiaNz/XX399+uKLL9K1116bQ0i49NJLc43OsGHDcngLUbsT8yPEbLjhhmm33XZL991330IFp1gvgt6bb76ZOnfunOfF/qPmKMJbr169co3UKaeckvcV1ltvvar147u41lGTF6K2rb4JTgAANC0t2v5f7U9j7LeO4mF+m222Sddcc00OTlEDEwNDnHPOOfn7qHn65S9/mUPMlClTcu3IrFmz6tyH6eWXX86BohyaQtQIze2vf/1r+v3vf5/+/e9/51quqLmJoFaJ2Nemm25aFZpC7969c63QhAkTqoLTRhttlENTWdQ+RfhZGOXzK4emEM0RYzCJ+C6C00knnZRrvq677rq04447pv333z/X2IXjjz8+/exnP0v33HNP/i5C1ML0K6uEPk4AADQt0fQtmsw19PT/m9zVVfRluvnmm9Onn36aa5vioX7bbbfN30VtVASaQYMG5dqVaGYWzeEiQC0qY8aMyc3ZfvjDH6Z//vOf6emnn85NBxflPqpr8f+byZVFE8UIV/UlRgR88cUXc83W/fffn4PVrbfemr+LQPXGG2/k5o8R3mJAjksuuSTVJ8EJAAAWQgxmsMwyy+SmbtHMLJrvlfs7PfbYY2nPPffMfXaiNieakr366qt13na3bt3SO++8k4cNL3viiSdqLPP444+nLl265LAUwSGassWgCdW1bNky134V7SsGYoi+TmVx/HFuG2ywQaoP3f7/+cVUFv2UPvnkkxyQymLgixNPPDHXLEWfrwioZVFbddRRR6VbbrklN4v84x//mOqT4AQAAAsh+g9FMBo8eHAOODHyXFmEmOinFAM7RNOzI488ssaIcUWi+VmEhgEDBuRQE80AIyBVF/uIvj7RHDCa6kUNV7lGpnq/p+hHFDVeU6dOzc0F5xa1VjFyX+wrBpOIwR+iT1bU5pSb6S2sCG2x7+pTXI84v+ifFPv+3//93zR27Ng84EbU2EUI/Pzzz/PgFDFQRITBCHLR9ykCV4iBMqL/V5xbrB/HXP6uvghOAACwkKK53rRp03IzvOr9kWLQhhgRbr/99svDfMfgDDGcd11FbU+EoAgQMZhENE2LPlPVRY1W1MZEwIjR7aIGKoYjry76/sTLemNY7xhCvbYh0aPfVYSQjz/+OPctimPeYYcd8kAQ39Rnn32Wr0P1KQadiJq522+/PQ84EUOuR5CKWrnosxWiL1UM6R5hKgJk1O7FwBgxvHo5kMXIehGW4vximcsuuyzVp2alUh0HrF9CxMgmMcpJDOlYacc5Gk68EyDG4o82u3O3p4XaKDNUSpmhUspM/YjR3KLWoGvXrrnWY0kS/X/Ko+pFEKLplbFKsoE7CAAAUEBwAgAAKCA4AQAAFBCcAAAACghOAAA0uqVsvDIWw7IlOAEA0GjKIxTOnDmzsQ+FJdSXX35ZNcT5N9F8ER0PAABULB5mV1pppfTBBx9UvVMo3vGzpAxHHg/tMRy24cgb7x58+OGHuVw1b/7Noo/gBABAo4qXw4ZyeFqSmojFC2zbtGmzxITBxVGE1rXXXvsb3wPBCQCARhUPtJ06dUqrrrpqftHwkiLO5eGHH04/+MEPvDS5EbVs2XKR1PgJTgAANJlme9+0H0pTEufy1VdfpdatWwtOSwCNLQEAAAoITgAAAAUEJwAAgAKCEwAAQAHBCQAAoIDgBAAAUEBwAgAAKCA4AQAAFBCcAAAACghOAAAABQQnAACAAoITAABAAcEJAACggOAEAABQQHACAAAoIDgBAAAUEJwAAAAKCE4AAAAFBCcAAIACghMAAEABwQkAAKCA4AQAAFBAcAIAACggOAEAABQQnAAAAAoITgAAAAUEJwAAgAKCEwAAQAHBCQAAoKkHp0mTJqX+/funDh06pDZt2qQePXqk8ePHL3CdWbNmpdNPPz116dIltWrVKq2zzjrpmmuuabBjBgAAli7NG3Pn06ZNS7179059+vRJo0aNSh07dkyvvfZaat++/QLXO+CAA9L777+frr766rTuuuumyZMnpzlz5jTYcQMAAEuXRg1Ow4YNS507d04jRoyomte1a9cFrnPXXXelhx56KL3xxhtp5ZVXzvOixgkAAGCJDE533HFH6tu3b9p///1zGFpzzTXT0UcfnQYOHLjAdXr27JkuuOCCdN1116Xlllsu7bnnnuncc8/NTf1qa9YXU9mMGTPyz9mzZ+eJpql8b9wj6kqZoVLKDJVSZqiUMtP0VXJvmpVKpVJqJK1bt84/TzrppByexo0blwYNGpSuuOKKNGDAgFrX2WWXXdKDDz6Ydtxxx3TWWWelqVOn5rAVzf2q11yVDRkyJA0dOnSe+ddff31q27ZtPZwVAACwOJg5c2Y66KCD0vTp01O7du2abnBq2bJlrj16/PHHq+Ydf/zxOUCNGTOm1nV23nnn9Mgjj6QpU6akFVdcMc+75ZZb0n777Zf+85//zFPrVFuNUzQPjMBVdHFo3PQ/evTotNNOO6UWLVo09uGwGFBmqJQyQ6WUGSqlzDR9kQ1WWWWVOgWnRm2q16lTp9S9e/ca87p165ZuvvnmBa4TTfrKoam8TuS/d999N6233no1lo9R92KaWxReBbjpc5+olDJDpZQZKqXMUCllpumq5L406nDkMaLehAkTasx79dVX8zDjC1rnvffeS5999lmNdZZZZpm01lpr1evxAgAAS6dGDU4nnnhieuKJJ9L555+fXn/99dzv6Morr0zHHHNM1TKDBw9OhxxySNXnaIMY73w67LDD0ksvvZQefvjhdMopp6TDDz+81sEhAAAAFuvg1KtXr3TrrbemG264IW288cZ5ZLzhw4enfv36VS0T72iaOHFi1efll18+txX95JNPcv+oWHaPPfZIv//97xvpLAAAgCVdo/ZxCrvvvnue5mfkyJHzzNtwww1zeAIAAFjia5wAAAAWB4ITAABAAcEJAACggOAEAABQQHACAAAoIDgBAAAUEJwAAAAKCE4AAAAFBCcAAIACghMAAEABwQkAAKCA4AQAAFBAcAIAACggOAEAABQQnAAAAAoITgAAAAUEJwAAgAKCEwAAQAHBCQAAoIDgBAAAUEBwAgAAKCA4AQAAFBCcAAAACghOAAAABQQnAACAAoITAABAAcEJAACggOAEAABQQHACAAAoIDgBAAAUEJwAAAAKCE4AAAAFBCcAAIACghMAAEABwQkAAKCA4AQAAFBAcAIAACggOAEAABQQnAAAAAoITgAAAAUEJwAAgAKCEwAAQAHBCQAAoIDgBAAAUEBwAgAAKCA4AQAAFBCcAAAACghOAAAABQQnAACAAoITAABAAcEJAACggOAEAABQQHACAAAoIDgBAAAUEJwAAAAKCE4AAAAFBCcAAIACghMAAEBTD06TJk1K/fv3Tx06dEht2rRJPXr0SOPHj5/v8g8++GBq1qzZPNOUKVMa9LgBAIClR/PG3Pm0adNS7969U58+fdKoUaNSx44d02uvvZbat29fuO6ECRNSu3btqj6vuuqq9Xy0AADA0qpRg9OwYcNS586d04gRI6rmde3atU7rRlBaaaWV6vHoAAAAmkBwuuOOO1Lfvn3T/vvvnx566KG05pprpqOPPjoNHDiwcN3NNtsszZo1K2288cZpyJAhueaqNrFMTGUzZszIP2fPnp0nmqbyvXGPqCtlhkopM1RKmaFSykzTV8m9aVYqlUqpkbRu3Tr/POmkk3J4GjduXBo0aFC64oor0oABA+bbRC/6OfXs2TMHoquuuipdd9116cknn0zf+c535lk+QtXQoUPnmX/99dentm3b1sNZAQAAi4OZM2emgw46KE2fPr1GN6AmF5xatmyZA9Djjz9eNe/444/PAWrMmDF13s62226b1l577Ryg6lLjFM0Dp06dWnhxaNz0P3r06LTTTjulFi1aNPbhsBhQZqiUMkOllBkqpcw0fZENVllllToFp0ZtqtepU6fUvXv3GvO6deuWbr755oq2s+WWW6ZHH3201u9atWqVp7lF4VWAmz73iUopM1RKmaFSygyVUmaarkruS6MORx79kqLpXXWvvvpq6tKlS0XbeeaZZ3IIAwAAqA+NWuN04oknpm222Sadf/756YADDkhjx45NV155ZZ7KBg8enN/1dO211+bPw4cPzyPvbbTRRumLL77IfZzuv//+dM899zTimQAAAEuyRg1OvXr1SrfeemsOR+ecc04ORBGM+vXrV7XM5MmT08SJE6s+f/nll+nkk0/OYSoGd9hkk03Svffem98FBQAAsMQFp7D77rvnaX5GjhxZ4/N///d/5wkAAKChNGofJwAAgMWB4AQAAFBAcAIAACggOAEAABQQnAAAAAoITgAAAAUEJwAAgAKCEwAAQAHBCQAAoIDgBAAAUEBwAgAAKCA4AQAAFBCcAAAACghOAAAABQQnAACAAoITAABAAcEJAACggOAEAABQQHACAAAoIDgBAAAUEJwAAAAKCE4AAAAFBCcAAIACghMAAEABwQkAAKCA4AQAAFBAcAIAACggOAEAABQQnAAAAAoITgAAAAUEJwAAgAKCEwAAQAHBCQAAoIDgBAAAUEBwAgAAKCA4AQAAFBCcAAAACghOAAAABQQnAACAAoITAABAAcEJAACggOAEAABQQHACAAAoIDgBAAAUEJwAAAAKCE4AAAAFBCcAAIACghMAAEABwQkAAKCA4AQAAFBAcAIAACggOAEAABQQnAAAAAoITgAAAPURnN5555307rvvVn0eO3ZsOuGEE9KVV165MJsDAABY8oLTQQcdlB544IH8+5QpU9JOO+2Uw9Ppp5+ezjnnnEV9jAAAAItfcHrhhRfSlltumX//29/+ljbeeOP0+OOPp7/85S9p5MiRi/oYAQAAFr/gNHv27NSqVav8+7333pv23HPP/PuGG26YJk+evGiPEAAAYHEMThtttFG64oor0iOPPJJGjx6ddtlllzz/vffeSx06dFjUxwgAALD4Badhw4alP/zhD2m77bZLBx54YNp0003z/DvuuKOqCV9dTZo0KfXv3z8HrjZt2qQePXqk8ePH12ndxx57LDVv3jxtttlmC3MaAAAAddI8LYQITFOnTk0zZsxI7du3r5p/xBFHpLZt29Z5O9OmTUu9e/dOffr0SaNGjUodO3ZMr732Wo1tzs8nn3ySDjnkkLTDDjuk999/f2FOAwAAoP6C0+eff55KpVJVwHn77bfTrbfemrp165b69u1bUc1V586d04gRI6rmde3atU7rHnXUUXl0v2WXXTbddtttC3EWAAAA9Ric9tprr7TPPvvk8BI1P1tttVVq0aJFroX67W9/m372s5/VaTvRtC+C1v77758eeuihtOaaa6ajjz46DRw4cIHrRdB644030p///Od03nnnLXDZWbNm5aksasnKA1zERNNUvjfuEXWlzFApZYZKKTNUSplp+iq5N81KUXVUoVVWWSUHnRgk4qqrrkqXXHJJevrpp9PNN9+czjrrrPTyyy/XaTutW7fOP0866aQcnsaNG5cGDRqUB54YMGBAretEU77vfe97eWCK9ddfPw0ZMiTXOD3zzDO1Lh/fDx06dJ75119/fUXNCgEAgCXLzJkzcyu26dOnp3bt2i36GqfYwQorrJB/v+eee3Lt0zLLLJO++93v5mZ7dTVnzpzUs2fPdP755+fPm2++eX5H1PyC09dff51PLIJQhKa6GDx4cA5m1WuconngzjvvXHhxaNz0HyM2xsuVozYTiigzVEqZoVLKDJVSZpq+cmu0ulio4LTuuuvmWp6999473X333enEE0/M8z/44IOKwkinTp1S9+7da8yLflJRc1WbTz/9NI+4F7Vbxx57bFX4ikqzGF0vQtz2229fY51431T5nVPVReFVgJs+94lKKTNUSpmhUsoMlVJmmq5K7stCBadojhc1PxGYIqhsvfXWeX4El6g1qqsYUW/ChAk15r366qupS5cutS4foez555+vMe+yyy5L999/f/r73/9e54ElAAAAKrFQwWm//fbL/YwmT55c9Q6nEEODRy1UXUXw2mabbXJTvQMOOCCNHTs2XXnllXmq3tQu3vV07bXX5uaAG2+8cY1trLrqqrmv1NzzAQAAGjU4hdVXXz1P7777bv681lprVfzy2169euVhzCMcnXPOObnGaPjw4alfv35Vy0Q4mzhx4sIeJgAAwDe2zMKsFP2KIuisuOKKuVldTCuttFI699xz83eV2H333XPzuy+++CKPxjf3UOQjR45MDz744HzXj1Hz5jeiHgAAQKPVOJ1++unp6quvTr/+9a9zP6Xw6KOP5hATAeiXv/zlIjk4AACAxTY4/elPf8rvb9pzzz2r5m2yySZVL7AVnAAAgLS0N9X7+OOP04YbbjjP/JgX3wEAAKSlPTjFSHqXXnrpPPNjXtQ8AQAALEkWqqneBRdckHbbbbd07733Vr3DacyYMemdd95Jd95556I+RgAAgMWvxmnbbbfNL6qNdzZ98sknedpnn33Siy++mK677rpFf5QAAACL43uc1lhjjXkGgXj22WfzaHvVX2ALAACwVNY4AQAALE0EJwAAgAKCEwAAwKLs4xQDQCxIDBIBAACwVAenFVdcsfD7Qw455JseEwAAwOIbnEaMGFF/RwIAANBE6eMEAABQQHACAAAoIDgBAAAUEJwAAAAKCE4AAAAFBCcAAIACghMAAEABwQkAAKCA4AQAAFBAcAIAACggOAEAABQQnAAAAAoITgAAAAUEJwAAgAKCEwAAQAHBCQAAoIDgBAAAUEBwAgAAKCA4AQAAFBCcAAAACghOAAAABQQnAACAAoITAABAAcEJAACggOAEAABQQHACAAAoIDgBAAAUEJwAAAAKCE4AAAAFBCcAAIACghMAAEABwQkAAKCA4AQAAFBAcAIAACggOAEAABQQnAAAAAoITgAAAAUEJwAAgAKCEwAAQAHBCQAAoIDgBAAAUEBwAgAAKCA4AQAAFBCcAAAACghOAAAABQQnAACAph6cJk2alPr37586dOiQ2rRpk3r06JHGjx8/3+UfffTR1Lt376rlN9xww3TxxRc36DEDAABLl+aNufNp06blENSnT580atSo1LFjx/Taa6+l9u3bz3ed5ZZbLh177LFpk002yb9HkDryyCPz70cccUSDHj8AALB0aNTgNGzYsNS5c+c0YsSIqnldu3Zd4Dqbb755nsrWWWeddMstt6RHHnlEcAIAAJa84HTHHXekvn37pv333z899NBDac0110xHH310GjhwYJ238fTTT6fHH388nXfeebV+P2vWrDyVzZgxI/+cPXt2nmiayvfGPaKulBkqpcxQKWWGSikzTV8l96ZZqVQqpUbSunXr/POkk07K4WncuHFp0KBB6YorrkgDBgxY4LprrbVW+vDDD9NXX32VhgwZks4888xal4vvhg4dOs/866+/PrVt23YRnQkAALC4mTlzZjrooIPS9OnTU7t27ZpucGrZsmXq2bNnrjEqO/7443OAGjNmzALXffPNN9Nnn32WnnjiiXTaaaelSy+9NB144IF1qnGK5oFTp04tvDg0bvofPXp02mmnnVKLFi0a+3BYDCgzVEqZoVLKDJVSZpq+yAarrLJKnYJTozbV69SpU+revXuNed26dUs333xz4brlvlAxCt/777+fa5ZqC06tWrXK09yi8CrATZ/7RKWUGSqlzFApZYZKKTNNVyX3pVGHI48R9SZMmFBj3quvvpq6dOlS0XbmzJlTo1YJAABgUWrUGqcTTzwxbbPNNun8889PBxxwQBo7dmy68sor81Q2ePDg/K6na6+9Nn/+n//5n7T22mvn9zeFhx9+OF100UW5iR8AAMASF5x69eqVbr311hyOzjnnnNz8bvjw4alfv35Vy0yePDlNnDixRu1SLB99nJo3b56+/e1v52HN411OAAAAS1xwCrvvvnue5mfkyJE1Ph933HF5AgAAaCiN2scJAABgcSA4AQAAFBCcAAAACghOAAAABQQnAACAAoITAABAAcEJAACggOAEAABQQHACAAAoIDgBAAAUEJwAAAAKCE4AAAAFBCcAAIACghMAAEABwQkAAKCA4AQAAFBAcAIAACggOAEAABQQnAAAAAoITgAAAAUEJwAAgAKCEwAAQAHBCQAAoIDgBAAAUEBwAgAAKCA4AQAAFBCcAAAACghOAAAABQQnAACAAoITAABAAcEJAACggOAEAABQQHACAAAoIDgBAAAUEJwAAAAKCE4AAAAFBCcAAIACghMAAEABwQkAAKCA4AQAAFBAcAIAACggOAEAABQQnAAAAAoITgAAAAUEJwAAgAKCEwAAQAHBCQAAoIDgBAAAUEBwAgAAKCA4AQAAFBCcAAAACghOAAAABQQnAACAAoITAABAAcEJAACggOAEAABQQHACAAAoIDgBAAAUEJwAAACaenCaNGlS6t+/f+rQoUNq06ZN6tGjRxo/fvx8l7/lllvSTjvtlDp27JjatWuXtt5663T33Xc36DEDAABLl0YNTtOmTUu9e/dOLVq0SKNGjUovvfRS+s1vfpPat28/33UefvjhHJzuvPPO9NRTT6U+ffqkPfbYIz399NMNeuwAAMDSo3lj7nzYsGGpc+fOacSIEVXzunbtusB1hg8fXuPz+eefn26//fb0j3/8I22++eb1dqwAAMDSq1GD0x133JH69u2b9t9///TQQw+lNddcMx199NFp4MCBdd7GnDlz0qeffppWXnnlWr+fNWtWnspmzJiRf86ePTtPNE3le+MeUVfKDJVSZqiUMkOllJmmr5J706xUKpVSI2ndunX+edJJJ+XwNG7cuDRo0KB0xRVXpAEDBtRpGxdccEH69a9/nV555ZW06qqrzvP9kCFD0tChQ+eZf/3116e2bdsugrMAAAAWRzNnzkwHHXRQmj59eh4/ockGp5YtW6aePXumxx9/vGre8ccfnwPUmDFjCteP8BO1U9FUb8cdd6xzjVM0D5w6dWrhxaFx0//o0aNzf7boAwdFlBkqpcxQKWWGSikzTV9kg1VWWaVOwalRm+p16tQpde/evca8bt26pZtvvrlw3RtvvDH99Kc/TTfddNN8Q1No1apVnuYWhVcBbvrcJyqlzFApZYZKKTNUSplpuiq5L406ql6MqDdhwoQa81599dXUpUuXBa53ww03pMMOOyz/3G233er5KAEAgKVdowanE088MT3xxBN5ZLzXX389N7278sor0zHHHFO1zODBg9MhhxxS9TmWic8xbPlWW22VpkyZkqeoXgMAAFjiglOvXr3SrbfemmuONt5443Tuuefm4cb79etXtczkyZPTxIkTqz5HsPrqq69yuIqmfuUpBpUAAACoD43axynsvvvueZqfkSNH1vj84IMPNsBRAQAANJEaJwAAgMWB4AQAAFBAcAIAACggOAEAABQQnAAAAAoITgAAAAUEJwAAgAKCEwAAQAHBCQAAoIDgBAAAUEBwAgAAKCA4AQAAFBCcAAAACghOAAAABQQnAACAAoITAABAAcEJAACggOAEAABQQHACAAAoIDgBAAAUEJwAAAAKCE4AAAAFBCcAAIACghMAAEABwQkAAKCA4AQAAFBAcAIAACggOAEAABQQnAAAAAoITgAAAAUEJwAAgAKCEwAAQAHBCQAAoIDgBAAAUEBwAgAAKCA4AQAAFBCcAAAACghOAAAABQQnAACAAoITAABAAcEJAACggOAEAABQQHACAAAoIDgBAAAUEJwAAAAKCE4AAAAFBCcAAIACghMAAEABwQkAAKCA4AQAAFBAcAIAACggOAEAABQQnAAAAAoITgAAAAUEJwAAgAKCEwAAQAHBCQAAoIDgBAAA0NSD06RJk1L//v1Thw4dUps2bVKPHj3S+PHj57v85MmT00EHHZTWX3/9tMwyy6QTTjihQY8XAABY+jRqcJo2bVrq3bt3atGiRRo1alR66aWX0m9+85vUvn37+a4za9as1LFjx3TGGWekTTfdtEGPFwAAWDo1b8ydDxs2LHXu3DmNGDGial7Xrl0XuM4666yTfve73+Xfr7nmmno/RgAAgEYNTnfccUfq27dv2n///dNDDz2U1lxzzXT00UengQMHLrJ9RA1VTGUzZszIP2fPnp0nmqbyvXGPqCtlhkopM1RKmaFSykzTV8m9aVYqlUqpkbRu3Tr/POmkk3J4GjduXBo0aFC64oor0oABAwrX32677dJmm22Whg8fPt9lhgwZkoYOHTrP/Ouvvz61bdv2G54BAACwuJo5c2YeP2H69OmpXbt2TTc4tWzZMvXs2TM9/vjjVfOOP/74HKDGjBmzSIJTbTVO0Txw6tSphReHxk3/o0ePTjvttFPuAwdFlBkqpcxQKWWGSikzTV9kg1VWWaVOwalRm+p16tQpde/evca8bt26pZtvvnmR7aNVq1Z5mlsUXgW46XOfqJQyQ6WUGSqlzFApZabpquS+NOqoejGi3oQJE2rMe/XVV1OXLl0a7ZgAAACaVI3TiSeemLbZZpt0/vnnpwMOOCCNHTs2XXnllXkqGzx4cH7X07XXXls175lnnsk/P/vss/Thhx/mz9Hsb+7aKwAAgMU+OPXq1SvdeuutORydc845eSjy6K/Ur1+/Gi+8nThxYo31Nt9886rfn3rqqTzQQ9RSvfXWWw16/AAAwNKhUYNT2H333fM0PyNHjpxnXiOOZwEAACyFGrWPEwAAwOJAcAIAACggOAEAABQQnAAAAAoITgAAAAUEJwAAgAKCEwAAQAHBCQAAoIDgBAAAUEBwAgAAKCA4AQAAFBCcAAAACghOAAAABQQnAACAAoITAABAAcEJAACggOAEAABQoHlaypRKpfxzxowZjX0oLMDs2bPTzJkz831q0aJFYx8OiwFlhkopM1RKmaFSykzTV84E5YywIEtdcPr000/zz86dOzf2oQAAAE0kI6y44ooLXKZZqS7xagkyZ86c9N5776UVVlghNWvWrLEPhwWk/wi377zzTmrXrl1jHw6LAWWGSikzVEqZoVLKTNMXUShC0xprrJGWWWbBvZiWuhqnuCBrrbVWYx8GdRR/yPiDhkooM1RKmaFSygyVUmaatqKapjKDQwAAABQQnAAAAAoITjRJrVq1SmeffXb+CXWhzFApZYZKKTNUSplZsix1g0MAAABUSo0TAABAAcEJAACggOAEAABQQHACAAAoIDjRKD7++OPUr1+//DK4lVZaKf3kJz9Jn3322QLX+eKLL9IxxxyTOnTokJZffvm07777pvfff7/WZT/66KP8ouNmzZqlTz75pJ7OgsW9zDz77LPpwAMPzG91b9OmTerWrVv63e9+1wBnQ334n//5n7TOOuuk1q1bp6222iqNHTt2gcvfdNNNacMNN8zL9+jRI9155501vo+xk84666zUqVOnXD523HHH9Nprr9XzWbC4lpnZs2enU089Nc9fbrnl0hprrJEOOeSQ9N577zXAmbC4/jlT3VFHHZWfW4YPH14PR84iEaPqQUPbZZddSptuumnpiSeeKD3yyCOlddddt3TggQcucJ2jjjqq1Llz59J9991XGj9+fOm73/1uaZtttql12b322qu06667xoiRpWnTptXTWbC4l5mrr766dPzxx5cefPDB0r///e/SddddV2rTpk3pkksuaYAzYlG68cYbSy1btixdc801pRdffLE0cODA0korrVR6//33a13+scceKy277LKlCy64oPTSSy+VzjjjjFKLFi1Kzz//fNUyv/71r0srrrhi6bbbbis9++yzpT333LPUtWvX0ueff96AZ8biUmY++eST0o477lj661//WnrllVdKY8aMKW255ZalLbbYooHPjMXpz5myW265Jf8dt8Yaa5QuvvjiBjgbFobgRIOLPzwi0IwbN65q3qhRo0rNmjUrTZo0qdZ14i+k+MPmpptuqpr38ssv5+3EX07VXXbZZaVtt902PywLTkuG+i4z1R199NGlPn36LOIzoL7FA+oxxxxT9fnrr7/ODyC/+tWval3+gAMOKO2222415m211ValI488Mv8+Z86c0uqrr1668MILa5SpVq1alW644YZ6Ow8W3zJTm7Fjx+Y/c95+++1FeOQsaWXm3XffLa255pqlF154odSlSxfBqQnTVI8GN2bMmNzUqmfPnlXzognMMsssk5588sla13nqqadyM4hYriyqvtdee+28vbKXXnopnXPOOenaa6/N22PJUJ9lZm7Tp09PK6+88iI+A+rTl19+me939XsdZSM+z+9ex/zqy4e+fftWLf/mm2+mKVOm1FhmxRVXzE1zFlR+WHrLzPz+PImmV/HnF4u3+iozc+bMSQcffHA65ZRT0kYbbVSPZ8Ci4MmSBhcPI6uuumqNec2bN88Pq/Hd/NZp2bLlPH/5rLbaalXrzJo1K/dXufDCC/PDMUuO+iozc3v88cfTX//613TEEUcswqOnvk2dOjV9/fXX+d7W9V7H/AUtX/5ZyTZZustMbX0so89T/L0UfTNZvNVXmRk2bFj+++z444+vpyNnURKcWGROO+20/C9rC5peeeWVetv/4MGDc+f+/v3719s+WLLKTHUvvPBC2muvvdLZZ5+ddt555wbZJ7BkitruAw44IA8wcvnllzf24dBERQ1WDEg0cuTI/PcdTV/zxj4Alhwnn3xyOvTQQxe4zLe+9a20+uqrpw8++KDG/K+++iqPmhbf1SbmRzV5jJBXvQYhRkgrr3P//fen559/Pv3973/Pn+MvrLDKKquk008/PQ0dOvQbnyNLVpmp3sRzhx12yDVNZ5xxxjc6Jxpe/D++7LLLzjPKZm33uizmL2j58s+YF6PqVV9ms802q4ezYHEvM3OHprfffjv/vaS2aclQH2XmkUceyX+3VW8lE7Va8XdjjKz31ltv1cu5sPDUOLHIdOzYMfchWdAUTae23nrr/DAb/9JSFn+5RDvf6D9Qmy222CK1aNEi3XfffVXzJkyYkCZOnJi3F26++eY8vPQzzzyTp6uuuqrqD6YYkpqmp7HLTHjxxRdTnz590oABA9Ivf/nLej5j6kOUkbjf1e91lI34XP1eVxfzqy8fRo8eXbV8165d88NN9WVmzJiR+9TNb5ss3WWmemiKYevvvffe/CoElgz1UWaib9Nzzz1X9dwSUwxjH/2d7r777no+IxZKY49OwdI7tPTmm29eevLJJ0uPPvpoab311qsxtHSMMLPBBhvk76sPLb322muX7r///jy09NZbb52n+XnggQeMqrcEqY8yE0PCduzYsdS/f//S5MmTq6YPPvigwc+Pbz5McIx4N3LkyDwK4xFHHJGHCZ4yZUr+/uCDDy6ddtppNYYJbt68eemiiy7Koy2effbZtQ5HHtu4/fbbS88991x+zYHhyJcci7rMfPnll3nI+rXWWqv0zDPP1PgzZdasWY12njTtP2fmZlS9pk1wolF89NFH+aF3+eWXL7Vr16502GGHlT799NOq7998880ceiL8lMXDSgwV3b59+1Lbtm1Le++9d/4LaX4EpyVLfZSZ+Ess1pl7ir+4WPzE+7ciKMd7VmLY4HjnV1m8omDAgAE1lv/b3/5WWn/99fPyG220Uelf//pXje9jSPIzzzyztNpqq+WHpR122KE0YcKEBjsfFq8yU/4zqLap+p9LLN4W9Z8zcxOcmrZm8Z/GrvUCAABoyvRxAgAAKCA4AQAAFBCcAAAACghOAAAABQQnAACAAoITAABAAcEJAACggOAEAABQQHACgAo0a9Ys3XbbbY19GAA0MMEJgMXGoYcemoPL3NMuu+zS2IcGwBKueWMfAABUIkLSiBEjasxr1apVox0PAEsHNU4ALFYiJK2++uo1pvbt2+fvovbp8ssvT7vuumtq06ZN+ta3vpX+/ve/11j/+eefT9tvv33+vkOHDumII45In332WY1lrrnmmrTRRhvlfXXq1Ckde+yxNb6fOnVq2nvvvVPbtm3Teuutl+64444GOHMAGpPgBMAS5cwzz0z77rtvevbZZ1O/fv3Sf/3Xf6WXX345f/ef//wn9e3bNwetcePGpZtuuinde++9NYJRBK9jjjkmB6oIWRGK1l133Rr7GDp0aDrggAPSc889l374wx/m/Xz88ccNfq4ANJxmpVKp1ID7A4Bv1Mfpz3/+c2rdunWN+b/4xS/yFDVORx11VA4/Zd/97nfTd77znXTZZZelP/7xj+nUU09N77zzTlpuueXy93feeWfaY4890nvvvZdWW221tOaaa6bDDjssnXfeebUeQ+zjjDPOSOeee25VGFt++eXTqFGj9LUCWILp4wTAYqVPnz41glFYeeWVq37feuuta3wXn5955pn8e9Q8bbrpplWhKfTu3TvNmTMnTZgwIYeiCFA77LDDAo9hk002qfo9ttWuXbv0wQcffONzA6DpEpwAWKxEUJm76dyiEv2e6qJFixY1PkfgivAFwJJLHycAlihPPPHEPJ+7deuWf4+f0fcpmteVPfbYY2mZZZZJG2ywQVphhRXSOuusk+67774GP24AmjY1TgAsVmbNmpWmTJlSY17z5s3TKquskn+PAR969uyZvve976W//OUvaezYsenqq6/O38UgDmeffXYaMGBAGjJkSPrwww/Tcccdlw4++ODcvynE/Ognteqqq+bR+T799NMcrmI5AJZeghMAi5W77rorDxFeXdQWvfLKK1Uj3t14443p6KOPzsvdcMMNqXv37vm7GD787rvvToMGDUq9evXKn2MEvt/+9rdV24pQ9cUXX6SLL744/fznP8+BbL/99mvgswSgqTGqHgBLjOhrdOutt6Yf/ehHjX0oACxh9HECAAAoIDgBAAAU0McJgCWG1ucA1Bc1TgAAAAUEJwAAgAKCEwAAQAHBCQAAoIDgBAAAUEBwAgAAKCA4AQAAFBCcAAAA0oL9P0t9Sd3CLCOSAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee8edbb",
   "metadata": {},
   "source": [
    "## 6. Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21f85089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 6.1580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load best model for evaluation\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss = evaluate(model, test_loader, device)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114f8291",
   "metadata": {},
   "source": [
    "## 7. Generate Example Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfa21b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example 1:\n",
      "Question: Are you tired?  You feel like you can --\n",
      "Actual answer: I'm everything, I'm banged up, I'm winded, I'm fatigued.  I've got all day tomorrow.  It's going to be tough to get some rest when you got a crazy two-year-old running around the house.  So hopefully I can take him to one of his grandma's house.\n",
      "Generated answer:  and I   I have to be a good team, I'm not going to be able to be the best in the game. That's what I'm going to do.\n",
      "\n",
      "\n",
      "\"I don't think we're going to have a lot of things to do, and I think we've got to be better. We've got a lot to do and I'm just going to try to do the best I can do. It's going to take a little bit of time to get better. I don't know what to do in the second half of the game, but I think that's what we're trying to do as a team. I just have to make sure we\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example 2:\n",
      "Question: In terms of style play, do you have to be mindful of whether it's running into a guy, whether you're going up for a foul, hard foul?\n",
      "Actual answer: Well, you just play the game the right way  At this point, you try to do whatever it takes to win  You don't want to hurt nobody  No one, I think, in our league goes around trying to hurt people, but you don't take the aggressive nature out of the game. I think in the case of‑‑ ever since you were a kid, the ball on the floor, the first man to the floor usually gets the ball  There's no difference between what Delly did to Kyle Korver last game and 18 guys diving on the floor late in the game tonight  It was like six or seven guys diving on the floor for that loose ball  Delly was on the floor  J.J. was on the floor  Mike Scott was on the floor  Shump was on the floor  J.R. was on the floor  Just no one got hurt. There's no difference between me boxing out or Al Horford boxing me out and Delly boxing someone out  That is a fundamental box‑out  That's all it is  And we all know that  We don't never want to play with the integrity of the game and try to get people hurt  That's not what it's about because we all want\n",
      "Generated answer:  the. we can't be able to have a lot in the game, and I'm going to try to get the ball in the end of the season. We've got to be a little bit of a team. I'm not going to be here. That's what we're going to do. It's a lot of fun. I think we've got a lot to do a lot more on the floor. We just have to be ready for the game. We'll try to be better. We have to play a lot better. So I think it's going to work\n",
      "\n",
      "Example 3:\n",
      "Question: LeBron, what was the breakdown defensively?\n",
      "Actual answer: A little bit of everywhere  I mean, they got some threes early on  Our pick‑and‑roll coverage had a lot of breakdowns, including myself; I broke down a few times defensively, and we allowed them to get into the paint  I mean, they shot 37 free throws to our 15, which is definitely something that we can't duplicate going into Game 2. But we had some breakdowns throughout the game, and that's what resulted in us losing this game  As a veteran ball club, we will watch the film and break it down and be better prepared in Game 2.\n",
      "Generated answer:  to the game. I'm going to be able to do a lot of the things I want to do. We're going to try to do that. I think we've got to go out there and try to make it a little bit better. We've got a chance to win the game, we have to play a couple of games. That's what we're trying to do and I'm just going to take advantage of it.\n",
      "\n",
      "\"I'm not going to give up on the ball. I don't know what to do in the second half of the game I'm trying to get the ball out of my hands, I'm not sure I can do that in the first half,\n"
     ]
    }
   ],
   "source": [
    "# Generate a few examples from the test set\n",
    "num_examples = 3\n",
    "test_samples = [test_dataset[i] for i in range(num_examples)]\n",
    "\n",
    "model.eval()\n",
    "for i, sample in enumerate(test_samples):\n",
    "    # Get the input data\n",
    "    stats = sample['stats'].unsqueeze(0).to(device)\n",
    "    input_ids = sample['input_ids'].unsqueeze(0).to(device)\n",
    "    attention_mask = sample['attention_mask'].unsqueeze(0).to(device)\n",
    "    \n",
    "    # Get the question\n",
    "    question = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Get the actual answer\n",
    "    actual_answer = tokenizer.decode(sample['labels'], skip_special_tokens=True)\n",
    "    \n",
    "    # Generate a response\n",
    "    generated_text = model.generate(\n",
    "        stats=stats,\n",
    "        prompt=question,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=150,\n",
    "        num_beams=5,\n",
    "        top_k=50,\n",
    "        top_p=0.9\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Actual answer: {actual_answer}\")\n",
    "    print(f\"Generated answer: {generated_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848a873c",
   "metadata": {},
   "source": [
    "## 8. Save Model and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0ddc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder for the final model\n",
    "output_dir = 'output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "model_path = os.path.join(output_dir, 'final_model.pt')\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "# Save the config\n",
    "config = {\n",
    "    'stats_input_dim': stats_input_dim,\n",
    "    'stats_hidden_dims': stats_hidden_dims,\n",
    "    'stats_output_dim': stats_output_dim,\n",
    "    'gpt_model_name': gpt_model_name,\n",
    "    'fusion_method': fusion_method,\n",
    "    'tokenizer_name': tokenizer_name,\n",
    "    'max_length': max_length,\n",
    "    'training_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    'final_train_loss': train_losses[-1],\n",
    "    'final_val_loss': val_losses[-1],\n",
    "    'test_loss': test_loss\n",
    "}\n",
    "\n",
    "with open(os.path.join(output_dir, 'model_config.json'), 'w') as f:\n",
    "    json.dump(config, f, indent=4)\n",
    "\n",
    "print(f\"Model saved to {model_path}\")\n",
    "print(f\"Config saved to {os.path.join(output_dir, 'model_config.json')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2f81f8",
   "metadata": {},
   "source": [
    "## 9. Inference Function for New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4469b71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(model, stats, question, tokenizer):\n",
    "    \"\"\"\n",
    "    Generate a response for a new game stats and question pair.\n",
    "    \n",
    "    Args:\n",
    "        model: The trained GameStats2TextGenerator model\n",
    "        stats: A list or numpy array of game statistics (matching the input dimensions)\n",
    "        question: The question to ask about the game\n",
    "        tokenizer: The GPT2 tokenizer\n",
    "    \n",
    "    Returns:\n",
    "        str: The generated response\n",
    "    \"\"\"\n",
    "    # Convert stats to tensor if needed\n",
    "    if not isinstance(stats, torch.Tensor):\n",
    "        stats = torch.tensor(stats, dtype=torch.float32)\n",
    "    \n",
    "    # Add batch dimension if needed\n",
    "    if stats.dim() == 1:\n",
    "        stats = stats.unsqueeze(0)\n",
    "    \n",
    "    # Move to device\n",
    "    stats = stats.to(device)\n",
    "    \n",
    "    # Generate text\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        response = model.generate(\n",
    "            stats=stats,\n",
    "            prompt=question,\n",
    "            tokenizer=tokenizer,\n",
    "            max_length=150,\n",
    "            num_beams=5,\n",
    "            top_k=50,\n",
    "            top_p=0.9\n",
    "        )\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c23bda",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "This notebook demonstrated the full pipeline for training and evaluating a GameStats2Text model that fuses basketball game statistics with text generation. The model learns to generate player-specific responses to questions about game performance.\n",
    "\n",
    "Next steps could include:\n",
    "\n",
    "1. Fine-tuning hyperparameters for better performance\n",
    "2. Experimenting with different model architectures\n",
    "3. Adding style conditioning to better capture player-specific language\n",
    "4. Implementing evaluation metrics like BERTScore or human evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a098944a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
