{
 "cells": [
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "id": "96d47cbf",
=======
   "cell_type": "code",
   "execution_count": 19,
   "id": "5325c7ca",
>>>>>>> 7bb357aba4f5cf95d8a7982a560ca275512e0ccd
   "metadata": {},
   "source": [
    "# GameStats2Text Main Notebook\n",
    "\n",
    "This notebook handles data setup, model initialization, training, saving, and generation for the GameStats2Text generator model."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "id": "149b32cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from src.process.setupData import GameStatsTextDataset, collate_fn\n",
    "from src.models.generator import GameStats2TextGenerator\n",
    "from transformers import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135f8a67",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set your paths, hyperparameters, and fusion method here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb397a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_CSV = 'data/dataset.csv'\n",
    "CHECKPOINT_DIR = 'checkpoints'\n",
    "BATCH_SIZE = 8\n",
    "LR = 1e-4\n",
    "EPOCHS = 3\n",
    "FUSION_METHOD = 'concat'  # or 'add'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee78a6bc",
   "metadata": {},
   "source": [
    "## Data Setup\n",
    "\n",
    "Load the dataset, split into training and validation sets, and create DataLoaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10fdcb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasonnair/Library/Caches/pypoetry/virtualenvs/game-stat-2-text-sARd-oMH-py3.12/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset = GameStatsTextDataset(csv_file=DATA_CSV)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f68a08",
   "metadata": {},
   "source": [
    "## Model Initialization\n",
    "\n",
    "Instantiate the generator model and move it to the appropriate device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12ee435b",
=======
   "execution_count": 20,
   "id": "900f9bab",
>>>>>>> 7bb357aba4f5cf95d8a7982a560ca275512e0ccd
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GameStats2TextGenerator(\n",
       "  (stats_encoder): StatsEncoder(\n",
       "    (encoder): Sequential(\n",
       "      (0): Linear(in_features=10, out_features=128, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=64, out_features=32, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (gpt2): GPT2LMHeadModel(\n",
       "    (transformer): GPT2Model(\n",
       "      (wte): Embedding(50257, 768)\n",
       "      (wpe): Embedding(1024, 768)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-11): 12 x GPT2Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D(nf=2304, nx=768)\n",
       "            (c_proj): Conv1D(nf=768, nx=768)\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D(nf=3072, nx=768)\n",
       "            (c_proj): Conv1D(nf=768, nx=3072)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "  )\n",
       "  (proj): Linear(in_features=800, out_features=768, bias=True)\n",
       ")"
      ]
     },
<<<<<<< HEAD
     "execution_count": 6,
=======
     "execution_count": 20,
>>>>>>> 7bb357aba4f5cf95d8a7982a560ca275512e0ccd
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
=======
    "df = pd.read_csv(\"data/dataset.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0437d24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1193, 9])\n"
     ]
    }
   ],
   "source": [
    "numeric_columns = ['PTS', 'AST', 'TRB', 'STL', 'BLK', 'FG%', 'TOV', 'PF', 'Result']\n",
    "stats_data = df[numeric_columns]\n",
    "\n",
    "stats_tensor = torch.tensor(stats_data.values, dtype=torch.float32)\n",
    "\n",
    "print(stats_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7155f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = stats_tensor.shape[1] \n",
    "encoder = StatsEncoder(input_dim=input_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95de380f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1193, 9])\n",
      "Output shape: torch.Size([1193, 32])\n",
      "Sample output embedding: tensor([-0.6002,  0.2090,  0.2591,  0.1426,  0.3316, -0.1448, -0.3543, -0.5936,\n",
      "         0.1252,  0.8496,  0.2295, -1.1668, -0.8630, -0.4952, -0.1707, -0.4865,\n",
      "        -0.1681,  0.3545,  0.9765,  0.0513, -0.3156, -0.0716, -0.0633,  0.1330,\n",
      "        -0.0977,  0.3412,  1.0113,  0.4359,  0.3955,  0.7559,  0.0026, -0.4129],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = encoder(stats_tensor)\n",
    "\n",
    "print(\"Input shape:\", stats_tensor.shape)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Sample output embedding:\", output[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ab9e3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "GameStats2TextModel = encoder_module.GameStats2TextModel\n",
    "\n",
    "df = pd.read_csv(\"data/dataset.csv\")\n",
    "batch = df.sample(4, random_state=0)\n",
    "\n",
    "stat_cols = ['PTS','AST','TRB','STL','BLK','FG%','TOV','PF', 'Result']\n",
    "stats = torch.tensor(batch[stat_cols].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ceba948",
   "metadata": {},
   "outputs": [],
   "source": [
>>>>>>> 7bb357aba4f5cf95d8a7982a560ca275512e0ccd
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "stats_input_dim = len(dataset.feature_cols)\n",
    "model = GameStats2TextGenerator(\n",
    "    stats_input_dim=stats_input_dim,\n",
    "    fusion_method=FUSION_METHOD\n",
    ")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "id": "2bf5d504",
=======
   "cell_type": "code",
   "execution_count": 26,
   "id": "4240b538",
>>>>>>> 7bb357aba4f5cf95d8a7982a560ca275512e0ccd
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "Run training and validation for a set number of epochs."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "id": "e30e6a45",
=======
   "execution_count": 27,
   "id": "7c10be11",
>>>>>>> 7bb357aba4f5cf95d8a7982a560ca275512e0ccd
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
=======
      " stats shape: torch.Size([4, 9])\n",
      " input_ids shape: torch.Size([4, 49])\n",
      " output shape: torch.Size([4, 49, 768])\n"
>>>>>>> 7bb357aba4f5cf95d8a7982a560ca275512e0ccd
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # Training\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        stats = batch['stats'].to(device)\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(stats, input_ids, attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch} | Train Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            stats = batch['stats'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(stats, input_ids, attention_mask, labels=labels)\n",
    "            total_val_loss += outputs.loss.item()\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    print(f\"Epoch {epoch} | Val   Loss: {avg_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da30bdd9",
   "metadata": {},
   "source": [
    "## Save Checkpoint\n",
    "\n",
    "Save the trained model for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0490a837",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "torch.save(model.state_dict(), os.path.join(CHECKPOINT_DIR, 'generator.pt'))\n",
    "print('Model saved to', os.path.join(CHECKPOINT_DIR, 'generator.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e23b9e",
   "metadata": {},
   "source": [
    "## Generation\n",
    "\n",
    "Load the checkpoint and generate a sample response given a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad24345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.process.setupData import GameStatsTextDataset\n",
    "from src.models.generator import GameStats2TextGenerator\n",
    "from transformers import GPT2Tokenizer\n",
    "import os, torch\n",
    "\n",
    "dataset = GameStatsTextDataset(csv_file=DATA_CSV)\n",
    "sample_stats = dataset.stats[-1]\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = GameStats2TextGenerator(\n",
    "    stats_input_dim=len(dataset.feature_cols),\n",
    "    fusion_method=FUSION_METHOD\n",
    ")\n",
    "model.load_state_dict(\n",
    "    torch.load(os.path.join(CHECKPOINT_DIR, 'generator.pt'), map_location=device)\n",
    ")\n",
    "model.to(device).eval()\n",
    "\n",
    "prompt = \"How do you feel about your performance tonight?\"\n",
    "response = model.generate(\n",
    "        stats=sample_stats,\n",
    "        prompt=prompt,\n",
    "        tokenizer=tokenizer)\n",
    "print(\"\\n--- GENERATED RESPONSE ---\\n\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a72f797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
<<<<<<< HEAD
  "language_info": {
   "name": "python"
=======
  "kernelspec": {
   "display_name": "game-stat-2-text-33nsFBE4-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
>>>>>>> 7bb357aba4f5cf95d8a7982a560ca275512e0ccd
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
