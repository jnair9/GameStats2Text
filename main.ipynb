{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96d47cbf",
   "metadata": {},
   "source": [
    "# GameStats2Text Main Notebook\n",
    "\n",
    "This notebook handles data setup, model initialization, training, saving, and generation for the GameStats2Text generator model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "149b32cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from src.process.setupData import GameStatsTextDataset, collate_fn\n",
    "from src.models.generator import GameStats2TextGenerator\n",
    "from transformers import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135f8a67",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set your paths, hyperparameters, and fusion method here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb397a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_CSV = 'data/dataset.csv'\n",
    "CHECKPOINT_DIR = 'checkpoints'\n",
    "BATCH_SIZE = 8\n",
    "LR = 1e-4\n",
    "EPOCHS = 3\n",
    "FUSION_METHOD = 'concat'  # or 'add'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee78a6bc",
   "metadata": {},
   "source": [
    "## Data Setup\n",
    "\n",
    "Load the dataset, split into training and validation sets, and create DataLoaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10fdcb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasonnair/Library/Caches/pypoetry/virtualenvs/game-stat-2-text-sARd-oMH-py3.12/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset = GameStatsTextDataset(csv_file=DATA_CSV)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f68a08",
   "metadata": {},
   "source": [
    "## Model Initialization\n",
    "\n",
    "Instantiate the generator model and move it to the appropriate device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12ee435b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GameStats2TextGenerator(\n",
       "  (stats_encoder): StatsEncoder(\n",
       "    (encoder): Sequential(\n",
       "      (0): Linear(in_features=10, out_features=128, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=64, out_features=32, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (gpt2): GPT2LMHeadModel(\n",
       "    (transformer): GPT2Model(\n",
       "      (wte): Embedding(50257, 768)\n",
       "      (wpe): Embedding(1024, 768)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-11): 12 x GPT2Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D(nf=2304, nx=768)\n",
       "            (c_proj): Conv1D(nf=768, nx=768)\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D(nf=3072, nx=768)\n",
       "            (c_proj): Conv1D(nf=768, nx=3072)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "  )\n",
       "  (proj): Linear(in_features=800, out_features=768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "stats_input_dim = len(dataset.feature_cols)\n",
    "model = GameStats2TextGenerator(\n",
    "    stats_input_dim=stats_input_dim,\n",
    "    fusion_method=FUSION_METHOD\n",
    ")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf5d504",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "Run training and validation for a set number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e30e6a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # Training\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        stats = batch['stats'].to(device)\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(stats, input_ids, attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch} | Train Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            stats = batch['stats'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(stats, input_ids, attention_mask, labels=labels)\n",
    "            total_val_loss += outputs.loss.item()\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    print(f\"Epoch {epoch} | Val   Loss: {avg_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da30bdd9",
   "metadata": {},
   "source": [
    "## Save Checkpoint\n",
    "\n",
    "Save the trained model for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0490a837",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "torch.save(model.state_dict(), os.path.join(CHECKPOINT_DIR, 'generator.pt'))\n",
    "print('Model saved to', os.path.join(CHECKPOINT_DIR, 'generator.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e23b9e",
   "metadata": {},
   "source": [
    "## Generation\n",
    "\n",
    "Load the checkpoint and generate a sample response given a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad24345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.process.setupData import GameStatsTextDataset\n",
    "from src.models.generator import GameStats2TextGenerator\n",
    "from transformers import GPT2Tokenizer\n",
    "import os, torch\n",
    "\n",
    "dataset = GameStatsTextDataset(csv_file=DATA_CSV)\n",
    "sample_stats = dataset.stats[-1]\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = GameStats2TextGenerator(\n",
    "    stats_input_dim=len(dataset.feature_cols),\n",
    "    fusion_method=FUSION_METHOD\n",
    ")\n",
    "model.load_state_dict(\n",
    "    torch.load(os.path.join(CHECKPOINT_DIR, 'generator.pt'), map_location=device)\n",
    ")\n",
    "model.to(device).eval()\n",
    "\n",
    "prompt = \"How do you feel about your performance tonight?\"\n",
    "response = model.generate(\n",
    "        stats=sample_stats,\n",
    "        prompt=prompt,\n",
    "        tokenizer=tokenizer)\n",
    "print(\"\\n--- GENERATED RESPONSE ---\\n\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a72f797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
