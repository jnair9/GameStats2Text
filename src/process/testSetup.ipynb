{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cefb51fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniforge/base/envs/cv_proj0/ml_hw4/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import sys, os\n",
    "from torch.utils.data import DataLoader\n",
    "from setupData import GameStatsTextDataset, collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa259b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniforge/base/envs/cv_proj0/ml_hw4/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Number of examples: 1193\n",
      "→ Stat feature columns (10): ['MP', 'PTS', 'FG%', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'Result']\n",
      "\n",
      "Sample[0]['stats'] shape: torch.Size([10])\n",
      "Sample[0]['input_ids'] shape: torch.Size([128])\n",
      "Sample[0]['attention_mask'] shape: torch.Size([128])\n",
      "Sample[0]['labels'] shape: torch.Size([128])\n",
      "\n",
      "Decoded question: I know you say that you're a football player, but do you think football players would get some fouls?\n",
      "Decoded answer:   (Laughing) It was definitely a physical game tonight.  You know, fouls were called at times and weren't called at times.  You know, this is what it's about.  You know, you can't look to get fouls and you've got to try to be as aggressive as possible.\n",
      "\n",
      "Batch shapes:\n",
      "  stats: torch.Size([4, 10])\n",
      "  input_ids: torch.Size([4, 128])\n",
      "  attention_mask: torch.Size([4, 128])\n",
      "  labels: torch.Size([4, 128])\n",
      "\n",
      "✅ setupData.py is loading and batching correctly!\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"/Users/josheevrai/CS4650/GameStats2Text/data/dataset.csv\"\n",
    "\n",
    "# 1. Instantiate the dataset\n",
    "dataset = GameStatsTextDataset(csv_file=csv_path, tokenizer_name='gpt2', max_length=128)\n",
    "\n",
    "# 2. Basic sanity checks\n",
    "print(f\"→ Number of examples: {len(dataset)}\")\n",
    "print(f\"→ Stat feature columns ({len(dataset.feature_cols)}): {dataset.feature_cols}\\n\")\n",
    "\n",
    "# 3. Inspect a single example\n",
    "sample = dataset[0]\n",
    "print(\"Sample[0]['stats'] shape:\", sample['stats'].shape)\n",
    "print(\"Sample[0]['input_ids'] shape:\", sample['input_ids'].shape)\n",
    "print(\"Sample[0]['attention_mask'] shape:\", sample['attention_mask'].shape)\n",
    "print(\"Sample[0]['labels'] shape:\", sample['labels'].shape)\n",
    "\n",
    "# 4. Decode to verify text alignment\n",
    "decoded_q = dataset.tokenizer.decode(sample['input_ids'],   skip_special_tokens=True)\n",
    "decoded_a = dataset.tokenizer.decode(sample['labels'],      skip_special_tokens=True)\n",
    "print(f\"\\nDecoded question: {decoded_q}\")\n",
    "print(f\"Decoded answer:   {decoded_a}\")\n",
    "\n",
    "# 5. Test batching\n",
    "loader = DataLoader(dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "batch = next(iter(loader))\n",
    "print(\"\\nBatch shapes:\")\n",
    "for k, v in batch.items():\n",
    "    print(f\"  {k}: {v.shape}\")\n",
    "\n",
    "print(\"\\n✅ setupData.py is loading and batching correctly!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbbb0500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([45.3667, 10.0000,  0.3330, 10.0000,  9.0000,  4.0000,  1.0000,  2.0000,\n",
      "         1.0000,  0.0000])\n"
     ]
    }
   ],
   "source": [
    "print(sample['stats'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b22af27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   40,   760,   345,   910,   326,   345,   821,   257,  4346,  2137,\n",
      "           11,   475,   466,   345,   892,  4346,  1938,   561,   651,   617,\n",
      "        15626,    82,    30, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256])\n"
     ]
    }
   ],
   "source": [
    "print(sample['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebbb4b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(sample['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5d51879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    7,    43,  1567,   278,     8,   632,   373,  4753,   257,  3518,\n",
      "          983,  9975,    13,   220,   921,   760,    11, 15626,    82,   547,\n",
      "         1444,   379,  1661,   290,  6304,   470,  1444,   379,  1661,    13,\n",
      "          220,   921,   760,    11,   428,   318,   644,   340,   338,   546,\n",
      "           13,   220,   921,   760,    11,   345,   460,   470,   804,   284,\n",
      "          651, 15626,    82,   290,   345,  1053,  1392,   284,  1949,   284,\n",
      "          307,   355,  8361,   355,  1744,    13, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256])\n"
     ]
    }
   ],
   "source": [
    "print(sample['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b46a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_hw4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
